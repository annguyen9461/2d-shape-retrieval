# -*- coding: utf-8 -*-
"""mag_conv_autoencoder.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NC2_4f8XOe7Ks-HsD8ibCS-aTHmagmgM
"""

# Commented out IPython magic to ensure Python compatibility.
__author__ = 'Vaibhav Kumar'

from __future__ import print_function, division
import os
import pandas as pd
from skimage import io, transform
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, utils
import cv2

from PIL import Image
from torch.nn.functional import interpolate

import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import matplotlib.pyplot as plt
from torch.utils.data.sampler import SubsetRandomSampler
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

import matplotlib.pyplot as plt
# %matplotlib inline
import torch.nn as nn
import torch.nn.functional as F

plt.ion()

"""https://analyticsindiamag.com/how-to-implement-convolutional-autoencoder-in-pytorch-with-cuda/ 
https://pytorch.org/tutorials/recipes/recipes/custom_dataset_transforms_loader.html
"""

# #Converting data to torch.FloatTensor
# transform = transforms.ToTensor()

# # Download the training and test datasets
# train_data = datasets.CIFAR10(root='data', train=True, download=True, transform=transform)
# test_data = datasets.CIFAR10(root='data', train=False, download=True, transform=transform)

# Dataset Class


class PNGDataset():
    """png dataset"""

    def __init__(self, root_dir, transform=None):
        """
        Args:
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.root_dir = root_dir
        self.transform = transform

    def __len__(self):
      root = self.root_dir
      list = os.listdir(root)
      count = len(list)
      print(count)
      return count

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()

        img_name = os.path.join(self.root_dir, str(idx)+".png")
        image = io.imread(img_name)
        sample = {'image': image}

        if self.transform:
            sample = self.transform(sample)

        return sample

# helper function to show image


def show_png(image):
    """Show image"""
    # NOT working for composed
    plt.imshow(image)
    plt.pause(0.001)  # pause a bit so that plots are updated

    # NOT working
    # if(len(image.shape) == 3):
    # plt.imshow(np.squeeze(image))
    #   print("RUNNN 3")
    # elif(len(image.shape) == 2):
    #   plt.imshow(image)
    #   print("RUNNN 2")
    # plt.pause(0.001)

    # plt.imshow( tf.shape( tf.squeeze(image) ) )

    # NOT working
    # if(len(image.shape) == 3):
    #   image = image.view(-1, 128**2)
    #   plt.imshow((image))
    # plt.pause(0.001)


def expand2square(pil_img, background_color):
  width, height = pil_img.size
  if width == height:
      return pil_img
  elif width > height:
      result = Image.new(pil_img.mode, (width, width), background_color)
      result.paste(pil_img, (0, (width - height) // 2))
      return result
  else:
      result = Image.new(pil_img.mode, (height, height), background_color)
      result.paste(pil_img, ((height - width) // 2, 0))
      return result


# Initialize dataset
png_dataset = PNGDataset(root_dir='/content/drive/MyDrive/png_files')

"""https://stackoverflow.com/questions/12201577/how-can-i-convert-an-rgb-image-into-grayscale-in-python"""

if os.path.isdir('/png_files_processed/'):
    print("Exists")
else:
    print("Doesn't exists")
    os.mkdir('/png_files_processed')

for i in range(len(png_dataset)-1):
  im = Image.open('/content/drive/MyDrive/png_files/'+str(i)+'.png')
  # Padding
  im_new = expand2square(im, (255, 255, 255))
  # Convert to grayscale
  im_new = im_new.convert('LA')
  im_new.save('/png_files_processed/'+str(i)+'.png', quality=95)

# Initialize dataset
png_dataset_processed = PNGDataset(root_dir='/png_files_processed')

"""https://pytorch.org/docs/stable/nn.functional.html?highlight=interpolate#torch.nn.functional.interpolate
https://www.programcreek.com/python/example/126478/torch.nn.functional.interpolate
"""


class ToTensor(object):
    """Convert ndarrays in sample to Tensors."""

    def __call__(self, sample):
        image = sample['image']

        # print(image.shape)
        # swap color axis because
        # numpy image: H x W x C
        # torch image: C X H X W
        image = image.transpose((2, 0, 1))
        return {'image': torch.from_numpy(image)}


class Resize(object):
    def __init__(self, output_size):
        assert isinstance(output_size, (int, tuple))
        self.output_size = output_size

    def __call__(self, sample):
        image = sample['image']
        image = image.unsqueeze(0)
        return {'image': F.interpolate(image, size=(self.output_size, self.output_size)).squeeze()}


# Converting data to torch.FloatTensor
transform = ToTensor()
composed = transforms.Compose([ToTensor(), Resize(128)])

# Download the training and test datasets
# train_data = datasets.CIFAR10(root='data', train=True, download=True, transform=transform)
# test_data = datasets.CIFAR10(root='data', train=False, download=True, transform=transform)

train_data = PNGDataset(root_dir='/png_files_processed', transform=composed)

for i in range(len(train_data)):
    sample = train_data[i]
    # print(type(sample['image']))
    print(i, sample['image'].size())

    if i == 4:
        break

#Prepare data loaders
train_loader = torch.utils.data.DataLoader(
    train_data, batch_size=32, num_workers=0)
# test_loader = torch.utils.data.DataLoader(test_data, batch_size=32, num_workers=0)

#Utility functions to un-normalize and display an image


def imshow(img):
    # img = img / 2 + 0.5          # don't need this line
    plt.imshow(np.transpose(img, (1, 2, 0)))


#Obtain one batch of training images
dataiter = iter(train_loader)
images = dataiter.next()
images = np.array(images['image'])  # convert images to numpy for display

#Plot the images
fig = plt.figure(figsize=(8, 8))
# display 20 images
for idx in np.arange(9):
    ax = fig.add_subplot(3, 3, idx+1, xticks=[], yticks=[])
    imshow(images[idx])

#Define the Convolutional Autoencoder


class ConvAutoencoder(nn.Module):
    def __init__(self):
        super(ConvAutoencoder, self).__init__()

        #Encoder
        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)
        self.conv2 = nn.Conv2d(16, 4, 3, padding=1)
        self.pool = nn.MaxPool2d(2, 2)

        #Decoder
        self.t_conv1 = nn.ConvTranspose2d(4, 16, 2, stride=2)
        self.t_conv2 = nn.ConvTranspose2d(16, 3, 2, stride=2)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = self.pool(x)
        x = F.relu(self.conv2(x))
        x = self.pool(x)
        x = F.relu(self.t_conv1(x))
        x = F.sigmoid(self.t_conv2(x))

        return x


#Instantiate the model
model = ConvAutoencoder()
print(model)

#Loss function
criterion = nn.BCELoss()

#Optimizer
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)


def get_device():
    if torch.cuda.is_available():
        device = 'cuda:0'
    else:
        device = 'cpu'
    return device


device = get_device()
print(device)
model.to(device)

#Epochs
n_epochs = 100

for epoch in range(1, n_epochs+1):
    # monitor training loss
    train_loss = 0.0

    #Training
    for data in train_loader:
        images = data['image']
        images = images.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, images)
        loss.backward()
        optimizer.step()
        train_loss += loss.item()*images.size(0)

    train_loss = train_loss/len(train_loader)
    print('Epoch: {} \tTraining Loss: {:.6f}'.format(epoch, train_loss))

#Batch of test images
dataiter = iter(test_loader)
images, labels = dataiter.next()

#Sample outputs
images = images.to(device)
output = model(images)
# images = images.numpy()
images = images.cpu().numpy()

batch_size = 32
output = output.view(batch_size, 3, 32, 32)
output = output.cpu()
#Original Images
print("Original Images")
fig, axes = plt.subplots(nrows=1, ncols=5, sharex=True,
                         sharey=True, figsize=(12, 4))
for idx in np.arange(5):
    ax = fig.add_subplot(1, 5, idx+1, xticks=[], yticks=[])
    imshow(images[idx])
    ax.set_title(classes[labels[idx]])
plt.show()

#Reconstructed Images
print('Reconstructed Images')
fig, axes = plt.subplots(nrows=1, ncols=5, sharex=True,
                         sharey=True, figsize=(12, 4))
for idx in np.arange(5):
    ax = fig.add_subplot(1, 5, idx+1, xticks=[], yticks=[])
    imshow(output[idx])
    ax.set_title(classes[labels[idx]])
plt.show()
